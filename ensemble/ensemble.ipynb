{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251709a4",
   "metadata": {},
   "source": [
    "# RecSys Model Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35271bbd",
   "metadata": {},
   "source": [
    "##### Using voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def ensemble_recommendations(folder_path, final_K, scaling_method='standard', weights=None): # weights : 가중치를 리스트 형태로\n",
    "    # 주어진 폴더에서 .csv 화일 목록 가져오기\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    # 각 화일을 데이터프레임으로 읽어오기\n",
    "    dfs = [pd.read_csv(os.path.join(folder_path, csv_file)) for csv_file in csv_files]\n",
    "    \n",
    "    # 가중치가 주어지지 않은 경우, 모든 알고리즘에 동일한 가중치 (1) 부여\n",
    "    if weights is None:\n",
    "        weights = [1] * len(dfs)\n",
    "    \n",
    "    # 스케일러 초기화\n",
    "    if scaling_method == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaling_method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "    # 모든 데이터프레임들을 하나로 합치기 전에 각 데이터프레임마다 prediction 값을 정규화\n",
    "    normalized_dfs = []\n",
    "    for i, df in enumerate(dfs):\n",
    "        df['prediction'] = scaler.fit_transform(df['prediction'].values.reshape(-1, 1)).flatten()\n",
    "        # 가중치 적용\n",
    "        df['prediction'] *= weights[i]\n",
    "        normalized_dfs.append(df)\n",
    "\n",
    "    # 정규화 및 가중치 적용된 데이터프레임들을 하나로 합치기\n",
    "    combined_df = pd.concat(normalized_dfs, ignore_index=True)\n",
    "    \n",
    "    # prediction 값을 추후 count해줄 컬럼 추가\n",
    "    combined_df['prediction_cnt'] =  combined_df['prediction']\n",
    "    \n",
    "    #resume_seq와 recruitment_seq를 기준으로 prediction 값을 그룹화하고 평균 계산\n",
    "    counted_predictions = combined_df.groupby(['resume_seq', 'recruitment_seq']).aggregate({'prediction':'mean','prediction_cnt':'count'}).reset_index()\n",
    "    \n",
    "    # 자주 등장한 값 내림차순 정렬 후, 같은 값에 대해서 prediction평균 내림차순 순\n",
    "    top_k = (\n",
    "        counted_predictions\n",
    "        .groupby('resume_seq')\n",
    "        .apply(lambda x: x.sort_values(by=['prediction_cnt','prediction'],ascending=[False,False]).head(5))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(top_k)\n",
    "    \n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef5cd3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      resume_seq recruitment_seq  prediction  prediction_cnt\n",
      "0         U00001          R01528    0.846749               6\n",
      "1         U00001          R00165    0.820276               6\n",
      "2         U00001          R06276    0.303367               6\n",
      "3         U00001          R03811    0.293427               6\n",
      "4         U00001          R02888    0.232514               6\n",
      "...          ...             ...         ...             ...\n",
      "42405     U08482          R04602    1.673135               6\n",
      "42406     U08482          R00712    0.370244               6\n",
      "42407     U08482          R00473    0.272431               6\n",
      "42408     U08482          R05461   -0.016783               6\n",
      "42409     U08482          R02524   -0.114000               6\n",
      "\n",
      "[42410 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 함수 호출\n",
    "recommendations = ensemble_recommendations('./preds', final_K=5)\n",
    "\n",
    "# 결과 저장\n",
    "t = pd.Timestamp.now()\n",
    "fname = f\"submit_ensemble_{t.month:02}{t.day:02}{t.hour:02}{t.minute:02}.csv\"\n",
    "recommendations[['resume_seq', 'recruitment_seq']].to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch2.0,Tensorflow2.12 (kaggle v135 23.07/ Python Conda 3.10,CUDA 11.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
